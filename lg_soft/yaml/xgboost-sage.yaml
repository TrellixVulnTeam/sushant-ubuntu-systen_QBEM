metaData:
  name: BatchInference1
  description: Sagemaker Model
  config: default
  version: 1.0
  team: "NLP" 

functional:
  process:
    input_content_type:
      dataType: string
      value: text/libsvm
    input_split_type:
      dataType: string
      value: Line
    output_assemble_with:
      dataType: string
      value: Line
    output_accept:
      dataType: string
      value: text/csv

deployment:
  type: batch_inference
  config:
    framework: xgboost        # pytorch | tensorflow | xgboost | chainer | scikit_learn | mx_net
    instance_count: 1
    instance_type: ml.p2.xlarge   # https://aws.amazon.com/sagemaker/pricing/

input:
  source:                                           # multiple sources could be present
    - filePath: 's3://testing-input-output-bucket/input/'   # file path - folder path
      name: "tripdata.csv"                              # file name
      srcType: S3                                # possibe values - s3 | local | MySQL
      type: python                                # possibe values - python | scala | jar
      argName: "inputfile"

output:
  dest:
    - fileName: xgboost_convert
      fileSourceType: S3
      contentType: Text/CSV/parquet
      filePath: ss3://testing-input-output-bucket/output
general:
  debug: no
  level: 1
  scriptFile: inference.py